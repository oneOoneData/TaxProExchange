---
title: "Tax Return Information Under §7216 and Your Firm’s Risk Line"
description: "Plain-English §7216 guide: why public chatbots can’t touch taxpayer data and how to deploy guardrailed AI with consent, logging, and encryption."
author: "Koen Van Duyse"
authorLinkedIn: "https://www.linkedin.com/in/koenvanduyse/"
authorReddit: "https://www.reddit.com/user/RepliKoen/"
authorTPE: "https://www.taxproexchange.com/p/koen-van-duyse-8123510e"
authorBio: "Koen has been working in AI for the last two years, with an emphasis on conversational AI. In his spare time he is partner of a small tax firm in Southern California and runs the Tax Pro Exchange."
authorImage: "/images/authors/koen-van-duyse.jpg"
date: "2025-11-15"
modified: "2025-11-15"
category: "AI"
pillar: "Future of Tax Work"
slug: "/ai/7216"
keywords:
  - "Section 7216"
  - "§7216 consent"
  - "tax return information"
  - "ChatGPT tax policy"
  - "AI compliance for tax firms"
  - "tax workflow automation"
  - "tax AI governance"
  - "SOC 2 for tax vendors"
  - "data processing agreement"
  - "taxpayer data security"
previewImage: "/images/the_hybrid_desk.png"
imageAlt: "Workstation with tax documents highlighted for AI review"
canonical: "https://www.taxproexchange.com/ai/7216"
readingTime: 11
robots: "index,follow"
tags:
  - "Compliance"
  - "Governance"
  - "Security"
  - "Best Practices"
ogTitle: "Tax Return Information Under §7216 and Your Firm’s Risk Line"
ogDescription: "A practical guide to keeping AI inside your §7216 guardrails, what’s safe, what isn’t, and how to deploy compliant, auditable workflows."
ogImage: "/images/the_hybrid_desk.png"
ogType: "article"
twitterCard: "summary_large_image"
twitterTitle: "§7216, Public Chatbots, and the Real AI Risk Line"
twitterDescription: "Teach teams where the AI guardrails live so you can stay compliant without killing velocity."
twitterImage: "/images/the_hybrid_desk.png"
schemaType: "Article"
---

About 14 days before the extension deadline, one of our junior team members copied a few lines from a client email into a public chatbot to wordsmith a response about a delayed K-1. She omitted names, skipped attachments, and thought the prompt was “generic.” It still included the partnership name, the client’s state, and a dollar amount. That single “innocent” request crossed the §7216 line in seconds. We did not have consent to send that data outside the firm. The teachable moment was clear: curiosity with public AI can quickly become an unintended disclosure.

Public chat tools are phenomenal for brainstorming headlines or simplifying dense writing. They are absolutely not where taxpayer information should live. This companion piece explains §7216 in plain language, highlights the patterns that keep tripping up otherwise trained teams, and proposes a practical, guardrailed way to apply AI without blowing up trust.

## What §7216 Really Covers, and Why AI Raises the Stakes

§7216 is a criminal statute, not a best-practices memo. Treasury Regulation §301.7216-1 defines tax return information broadly: anything furnished by or on behalf of a taxpayer for return prep, plus anything created in connection with that prep. Names, addresses, EINs, W-2 values, K-1 snippets, the mere fact that someone is your client, they all qualify. Disclosing or using that information for any purpose other than preparing or assisting with the return requires explicit, written consent.

Publicly accessible AI tools create two immediate compliance risks: **destination risk** (you transmit data into a system you do not control, where prompts may be logged for abuse prevention or telemetry) and **workflow gaps** (no §7216 consent, audit trail, or log that ties the specific client data back to a legitimate use). Even a quick copy/paste can become a noncompliant disclosure if the data entered originated from return prep.

## How Firms Accidentally Violate §7216 with AI

- “Summarize this K-1” by uploading the PDF to a chatbot so you can draft an email, instant disclosure.  
- “Draft a letter responding to this IRS notice” using the notice date, balance, or identifying facts, each item is tax return information.  
- “What’s the best state filing position?” while leaving the partnership name, state, or dollar amounts intact.  
- “Brainstorm a planning memo” that cites the client’s industry and comp structure; combined facts can pinpoint the client.

Intent does not matter, scope does. If the info came from return prep or was created during prep, it is protected.

## Safe vs. Unsafe Prompts

**Safe with public LLMs (no client data):** drafting engagement letter templates with placeholders, brainstorming blog titles, summarizing IRS publications, or writing internal SOPs with fictional data.  
**Not safe:** summarizing or extracting from W-2s, K-1s, prior returns, or notices; drafting client-specific emails; researching positions with identifiable facts; posting any client PDFs or screenshots, even if “redacted” by hand.  
**Potentially safe with the right vendor controls:** AI research or extraction tools that live inside a contracted environment with §7216 consent flows, tenant isolation, encryption, audit logging, and an explicit no-training guarantee. That is the “guardrailed AI” zone.

## Building a Guardrailed AI Workflow

1. **Find a provider built for tax data.** They should supply §7216-ready consent language, isolate your tenant, encrypt data at rest/in transit, log every action, and back it with SOC 2 or ISO 27001 evidence.  
2. **Create a Red/Green prompt policy.** Green = generic writing, public summaries, templates. Red = anything with client-specific facts, numbers, PDFs, or context drawn from return prep. Train with real firm examples so staff see the line.  
3. **Put AI inside your workflow.** Integrate the approved tool with your DMS and prep software. If people have to open a separate public tab, you’ve already lost the audit trail.  
4. **Align consent language with reality.** Cover secure extraction, organization, and drafting solely for preparing and filing returns. Store the consent with the client’s file and allow revocation at any time.  
5. **Maintain human-in-the-loop.** AI drafts; humans review exceptions, document overrides, and sign off. Require notes when preparers adjust AI outputs so reviewers understand the delta.  
6. **Quantify the win.** Track minutes per return, exceptions per return, first-pass yield, and cycle time. Metrics prove that compliant AI still delivers speed.

## Thought Experiments to Teach the Line

**Querying prior-year data for missed state filings:** run it through a public chatbot and you’ve exported taxpayer data. Run it through a vendor integrated with your DMS, backed by consent, logging, and encryption, and you have an auditable time saver.  
**Client email drafts with citations:** public tools can produce friendly prose but no review trail. An internal, controlled tool can generate the same narrative with links back to workpapers, preserving accountability.

## “But Our Enterprise Plan Says Prompts Aren’t Used for Training”

Great, but §7216 cares about disclosure and use, not only training. Even if you trust the provider’s promise, you still need technical controls, encryption, isolation, logging, retention limits, and the ability to prove compliance later. Without those controls the best you can show auditors is an access log, not a defensible consent trail.

## Simple Policy You Can Roll Out Today

**Policy statement (plain language):** “We do not put client data into public chatbots nor upload client documents into tools that are not approved for handling tax data. We use firm-approved AI tools that provide §7216 consent, encrypt data, log access, and guarantee ‘no training.’ Staff may use public AI for generic writing and public summaries but must exclude any client-identifying facts or return-derived numbers.”  
**Consent blurb (review with counsel):** “We utilize secure, third-party processing tools to extract, classify, and organize your tax documents solely for preparing and filing your tax return(s). Your data remains encrypted in transit and at rest, is not used to train models, and is not shared outside your engagement. You may revoke consent at any time by emailing [Your Firm Contact].”  
**Training materials:** one-page red/green prompt examples sourced from your files, a screenshot walkthrough of the approved AI flow, and a short quiz managers can deploy in team meetings.

## The Payoff: AI Still Helps, In the Right Lane

Once guardrails are in place, AI delivers research answers with footnotes that juniors can follow, produces review-ready returns with linked workpapers, nudges staff past workflow bottlenecks, and drafts emails that link directly to supporting numbers. Humans keep judgment, communication, and signatures; AI handles extraction, summarization, and comparison. That division of labor respects §7216 and lets your clients sleep at night.

**Your turn:** How do you approach §7216 in your AI policy? Do you allow public tools for generic writing, or have you disabled them entirely? What does your consent language cover, and how are you training teams on red vs. green prompts? Let me know, and if you need a purpose-built AI research environment, [tools](/ai/tools) exist to keep client data in a compliant lane.

